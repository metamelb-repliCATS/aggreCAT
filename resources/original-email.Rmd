---
title: "original email from elise"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# key info

- each method is summarised in the document “Aggregation methods_Summary_Unimelb”
- mathematical notation along with free-text is described in the attached document “EQUATIONS Aggregations_v3AH”
- The function should take one or more dataframes as their argument, depending on their input requirements, and return a single dataframe in the following format


```
MethodID | Method_NumID | ClaimID | ConfidenceScore 
```

Where MethodID is the Abbreviation of the method title (see aggregation methods summary doc), Method_NumID is the number of each of the method (just take the order from the Aggregation methods Summary doc for now). ClaimID refers to the identity of the claim. For every unique claim id, there will be one observation, i.e. row, and a corresponding ConfidenceScore. The aggregation functions should calculate a ConfidenceScore for every claim.


# original email from Elise:

Our requirements for the task are outlined below. If you have any questions please don’t hesitate to contact me via email or on the phone +61406680382 for clarification.

We have a number of aggregation methods that we would like you to write code for, each method is summarised in the document “Aggregation methods_Summary_Unimelb”. The mathematical notation along with free-text is described in the attached document “EQUATIONS Aggregations_v3AH”.

For each of the aggregation methods, we would like one function, ideally written in R, but open to implementations in other languages —  such as python, if you have a strong preference (please discuss this in person with me if so).

The function should take one or more dataframes as their argument, depending on their input requirements, and return a single dataframe in the following format (welcome to swap out the CamelCase for your own preferred variable name format, as long as it’s consistent):

```
MethodID | Method_NumID | ClaimID | ConfidenceScore 
```

Where MethodID is the Abbreviation of the method title (see aggregation methods summary doc), Method_NumID is the number of each of the method (just take the order from the Aggregation methods Summary doc for now). ClaimID refers to the identity of the claim. For every unique claim id, there will be one observation, i.e. row, and a corresponding ConfidenceScore. The aggregation functions should calculate a ConfidenceScore for every claim.

## Aggregation Method Inputs & dependencies

I have set up a spreadsheet summarising the data input, and code dependencies for each aggregation method / function https://docs.google.com/spreadsheets/d/1B3_BqrwkW4pxmGLW-mK-7IeDFNCC1CuXs-yXfQ3IAGE/edit?usp=sharing. The majority of the methods take expert judgments from the dataset NAME
 EXPORT DATASET.csv, however some functions take data from external datasets in addition to the expert data, these are marked in the column “External Data or Other Aggregation Measures as Inputs”.

The Bayesian methods will require the use of jags code, and some data wrangling to get the data into the format for the jags code, and then some more wrangling to extract the required data from the jags output. I’m on the team responsible for the BayPRIORsAgg, so can provide this to you to functionalise.

I’m currently unsure of the format for the external dataset for QuizWAgg and ReasonWAgg, but will get back to you about this once I have more information from the RepliCATS Teams responsible for this data.

## Platform Data Inputs

The primary input file for computing the ConfidenceScores has the following format:

```

round | paper_id | user_name |question | element | value | timestamp
```

See a sample file with actual data from the platform: https://drive.google.com/file/d/13c2dnRNAU3779TXwfVlH2I1JGiex0sDw/view?usp=sharing Please note, this dataset contains identifying data.

Each observation in the data set is a value for a particular element of a user_id’s judgment about the likely reproducibility of the paper_idor claim under consideration. Please note that paper_id in this dataset refers to ClaimID in the output dataframe of each aggregation function.

You will only need the rows where question
 == "direct_replication" The element refers to the upper and lower bounds, as well as the Best estimate by each user_id about the chance that the corresponding paper_id will replicate successfully,.

round refers to which round the judgments came from. To refresh your memory on the IDEA protocol we used to obtain these judgments, each individual provides judgments in a first round of elicitation round
 ==round_1, which is followed by group discussion, and then participants may choose to adjust their judgments (or not) in a second round of elicitation round
 == round_2. Most of the methods use the round 2 judgments, however I think there is at least one that uses round2 judgments, but this is all explained in Bonnie’s Aggregation Methods Equations doc.



## Pipelines and Piecing it all Together

In terms of a pipeline and order of aggregation calculation for the entire collation workflow, some methods depend on others already having been calculated because they take in weights or outputs from other aggregation methods. I’ve marked these in the column “External Data or Other Aggregation Measures as Inputs”. But it will be obvious from the description in the aggregation methods equation doc.

We’re open to you piecing the pipeline of functions together in anyway you see fit, whether that’s some neat combination of purrr and list-columns, or simply a master script that applies all of the functions and row binds each functions’ dataframes together.

The objective is to spit out a single file with a single ConfidenceScore for every claimID, for every methodID


## Collaboration Workflow

How do you feel about working on GitHub so we can use GitHub Issues to discuss any problems? I’ve set up an empty repository for this task. I’ll invite you after I send this email. Basically this repository is for you to lead the dev on and do whatever you like on it. Feel free to ping me in the repo as you need.

Any specific questions about the aggregation methods, and their interpretation (aside from the BayPRIORsAgg) should be directed to Bonnie (CC’d). 

Please let me know if you require further information.
